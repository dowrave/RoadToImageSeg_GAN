{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220511_Adversarial_Examples.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNYWqq8jQFjKrNzzketf+4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/RoadToImageSeg_GAN/blob/main/220511_Adversarial_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 적대적 샘플(Adversarial Example)\n",
        "- 신경망을 혼란시킬 목적으로 만든 특수한 입력.\n",
        "- 머신러닝 모델은 자연 발생한 샘플은 잘 대응하지만 이런 샘플에는 잘 대응하지 못함\n",
        "\n",
        "- 신경망 공격 기술에 여러 종류가 있다.\n",
        "- 이번 튜토리얼에서는 화이트 박스(White Box) 공격 기술에 속하는 FGSM을 다룬다.\n",
        "  - 화이트 박스 : 공격자가 대상 모델의 모든 파라미터 값에 접근할 수 있다는 가정 하에 이루어지는 공격\n",
        "  - FGSM(Fast Gradient Sign Method) : 그래디언트를 이용해 적대적 샘플을 생성하는 기법. 입력 이미지에 대한 손실 함수의 그래디언트를 계산, 손실을 최대화하는 이미지를 생성한다.\n",
        "    - A.E.는 각 픽셀의 손실에 대한 기여도를 그래디언트를 통해 계산 -> 기여도에 따라 픽셀 값에 왜곡을 추가하여 생성. 기여도는 Chain Rule을 이용해 그래디언트를 계산한다. \n",
        "    - 대상 모델(학습을 마친 모델)은 더 이상 학습하지 않기 때문에 모델의 가중치 값은 유지된다."
      ],
      "metadata": {
        "id": "sgB6HT71jWE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rEPAYQKbc7I"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 8)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 훈련된 MobileNetV2 모델과 imageNet의 클래스 이름들을 불러온다."
      ],
      "metadata": {
        "id": "sq8YBuZhk7LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(include_top = True,\n",
        "                                                    weights = 'imagenet')\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "# ImageNet 클래스 레이블\n",
        "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
      ],
      "metadata": {
        "id": "oS58_tKOk0nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 전달 전처리 \n",
        "def preprocess(image):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = image / 255\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "  image = image[None, ...]\n",
        "  return image\n",
        "\n",
        "# 확률 벡터에서 레이블 추출\n",
        "def get_imagenet_label(probs):\n",
        "  return decode_predictions(probs, top=1)[0][0]"
      ],
      "metadata": {
        "id": "1vIgtUNjlJeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레브라도 리트리버 샘플 이미지\n",
        "image_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
        "image_raw = tf.io.read_file(image_path)\n",
        "\n",
        "# 이미지 디코딩 - 전처리 - 입력으로 넣음\n",
        "image = tf.image.decode_image(image_raw)\n",
        "image = preprocess(image)\n",
        "image_probs = pretrained_model.predict(image)"
      ],
      "metadata": {
        "id": "JH8FnLpEleQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(image[0])\n",
        "_, image_class, class_confidence = get_imagenet_label(image_probs)\n",
        "plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence * 100))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TNjNBMMMl2Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 적대적 이미지 생성하기\n",
        "1. FGSM 실행"
      ],
      "metadata": {
        "id": "IGQi4zkxmVDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "def create_adversarial_pattern(input_image, input_label):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input_image)\n",
        "    prediction = pretrained_model(input_image)\n",
        "    loss = loss_object(input_label, prediction)\n",
        "\n",
        "  # 입력 이미지에 대한 손실 함수 기울기\n",
        "  gradient = tape.gradient(loss, input_image)\n",
        "\n",
        "  # 왜곡 생성 : 그래디언트 부호를 얻음\n",
        "  signed_grad = tf.sign(gradient)\n",
        "  return signed_grad\n"
      ],
      "metadata": {
        "id": "8ji3o_3AmP3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왜곡 시각화\n",
        "labrador_retriever_index = 208\n",
        "label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
        "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
        "\n",
        "perturbations = create_adversarial_pattern(image, label)\n",
        "plt.imshow(perturbations[0])"
      ],
      "metadata": {
        "id": "blUOBW0tnhWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(image, description):\n",
        "  _, label, confidence = get_imagenet_label(pretrained_model.predict(image))\n",
        "  plt.figure()\n",
        "  plt.imshow(image[0])\n",
        "  plt.title('{} \\n {} : {:.2f}% Confidence'.format(description, label, confidence * 100))\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "V-WJjZexns_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0, 0.01, 0.1, 0.15]\n",
        "descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input') for eps in epsilons]\n",
        "\n",
        "for i, eps in enumerate(epsilons):\n",
        "  adv_x = image + eps * perturbations\n",
        "  adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
        "  display_images(adv_x, descriptions[i])"
      ],
      "metadata": {
        "id": "2m9A1olUoL4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BX_ANlctoZ-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}