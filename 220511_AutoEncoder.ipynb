{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220511_AutoEncoder.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPPe81ppEEFRqZilDUvZVq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/RoadToImageSeg_GAN/blob/main/220511_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[텐서플로우 튜토리얼](https://www.tensorflow.org/tutorials/generative/autoencoder?hl=ko)"
      ],
      "metadata": {
        "id": "EV1flZhn4wGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AutoEncoder\n",
        "- 입력을 출력에 복사하도록 훈련된 특수한 유형의 신경망\n",
        "- 이미지 -> 낮은 차원의 잠재 표현 (인코딩) -> 이미지 (디코딩)\n",
        "  - 재구성 오류를 최소화하면서 데이터 압축 방법을 학습함"
      ],
      "metadata": {
        "id": "82lGAGS042a0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxoYDuES2hY2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "mDhDKpP55Eff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2개의 Dense Layer로 AutoEncoder 정의하기\n",
        "latent_dim = 64\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, encoding_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    # encoder : input 이미지 -> Flatten -> latent_dim 개로 축소\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "                                        layers.Flatten(),\n",
        "                                        layers.Dense(latent_dim, activation = 'relu') # relu를 쓰네~\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "                                        layers.Dense(784, activation = 'sigmoid'), # sigmoid를 쓰네~\n",
        "                                        layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder(latent_dim)"
      ],
      "metadata": {
        "id": "EDzcVkYs5WEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer = 'adam', loss = losses.MeanSquaredError())"
      ],
      "metadata": {
        "id": "mLMO3mOh6B4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 : Model을 상속받았으니 fit도 가능하겠죠?\n",
        "autoencoder.fit(x_train, x_train, # Target이 x_train인 것에 유의!\n",
        "                epochs = 10,\n",
        "                shuffle = True,\n",
        "                validation_data = (x_test, x_test))"
      ],
      "metadata": {
        "id": "Qu2IlQtB6QpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ],
      "metadata": {
        "id": "RRF4Qcqh6zCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize = (20, 4))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i+1)\n",
        "  plt.imshow(x_test[i])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  ax = plt.subplot(2, n, i+1+n)\n",
        "  plt.imshow(decoded_imgs[i])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I_Pg6Ce266He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예제 2. 이미지 노이즈 제거"
      ],
      "metadata": {
        "id": "8f8ofMRE7d4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "cIbnDw2e7VhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]\n",
        "\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "fe0Ds3cw7joK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.2\n",
        "x_train_noisy = x_train + noise_factor * tf.random.normal(shape = x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * tf.random.normal(shape = x_test.shape)\n",
        "\n",
        "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min = 0., clip_value_max = 1.)\n",
        "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min = 0., clip_value_max = 1.)"
      ],
      "metadata": {
        "id": "pxw9NPL77tSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AnAXeXJr9zLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 노이즈 이미지 플롯하기\n",
        "n = 10\n",
        "plt.figure(figsize = (20, 2))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(1, n, i+1)\n",
        "  plt.title(\"original + noise\")\n",
        "  plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
        "  plt.gray()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h-AAEnFG8Jed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Autoencoder 정의하기"
      ],
      "metadata": {
        "id": "aPTLU17l8va3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Denoise(Model):\n",
        "  def __init__(self):\n",
        "    super(Denoise, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(28, 28, 1)), \n",
        "      layers.Conv2D(16, (3,3), activation='relu', padding='same', strides=2),\n",
        "      layers.Conv2D(8, (3,3), activation='relu', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "\n",
        "autoencoder = Denoise()"
      ],
      "metadata": {
        "id": "RZBsmKYG8uIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer = 'adam', loss = losses.MeanSquaredError())\n",
        "\n",
        "# 노이즈 데이터와 원본 데이터를 같이 넣음 -> 노이즈를 제거하도록 학습\n",
        "autoencoder.fit(x_train_noisy, x_train, epochs = 10, shuffle  = True, validation_data = (x_test_noisy, x_test)) "
      ],
      "metadata": {
        "id": "C91mR6NU8uK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(autoencoder.encoder.summary())\n",
        "print(autoencoder.decoder.summary())"
      ],
      "metadata": {
        "id": "mSxh9WqO8uNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ],
      "metadata": {
        "id": "us3gpFTD8uPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10\n",
        "plt.figure(figsize = (20, 4))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i+1)\n",
        "  plt.title(\"original + noise\")\n",
        "  plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  ax = plt.subplot(2, n, i+1+n)\n",
        "  plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-uOOyNovAxLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 이상 감지\n",
        "- ECG5000 (심전도) 데이터세트에서 이상 감지하는 훈련\n",
        "- 140개의 포인트, 5000개의 샘플\n",
        "- 각 예제는 0(비정상), 1(정상) 으로 레이블이 지정되어 있음\n"
      ],
      "metadata": {
        "id": "MUCCu1UyBNti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header = None)\n",
        "raw_data = dataframe.values\n",
        "dataframe.head()"
      ],
      "metadata": {
        "id": "sRvuDHvNBBqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 마지막 element는 label\n",
        "labels = raw_data[:, -1]\n",
        "\n",
        "# 그 앞의 element들은 심전도 데이터\n",
        "data = raw_data[:, 0:-1]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size = 0.2, random_state = 21\n",
        ")"
      ],
      "metadata": {
        "id": "4kJeooS1Bg4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화\n",
        "min_val = tf.reduce_min(train_data) # 텐서 차원의 요소 중 최솟값 구하기\n",
        "max_val = tf.reduce_max(train_data)\n",
        "\n",
        "# minmax Normalization\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "test_data = tf.cast(test_data, tf.float32)"
      ],
      "metadata": {
        "id": "HPEW0o4yByqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정상 리듬(label = 1)만 사용하여 autoencoder 훈련\n",
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_test_data = test_data[test_labels]\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_test_data = test_data[~test_labels]"
      ],
      "metadata": {
        "id": "A3xiYyfmCJ8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정상 ECG 플롯\n",
        "plt.grid()\n",
        "plt.plot(np.arange(140), normal_train_data[0])\n",
        "plt.title('A Normal ECG')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dz4WOfo8Cjuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비정상 ECG 플롯\n",
        "plt.grid()\n",
        "plt.plot(np.arange(140), anomalous_train_data[0])\n",
        "plt.title('A Normal ECG')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xBnaGbKJCptH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 빌드\n",
        "class Anomalydetector(Model):\n",
        "  def __init__(self):\n",
        "    super(Anomalydetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "                                        layers.Dense(32, activation = 'relu'),\n",
        "                                        layers.Dense(16, activation = 'relu'),\n",
        "                                        layers.Dense(8, activation = 'relu')\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "                                        layers.Dense(16, activation = 'relu'),\n",
        "                                        layers.Dense(32, activation = 'relu'),\n",
        "                                        layers.Dense(140, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "  \n",
        "autoencoder = Anomalydetector()"
      ],
      "metadata": {
        "id": "M8DI1J-mCwRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer = 'adam', loss = 'mae')"
      ],
      "metadata": {
        "id": "cFQpwA0GDOq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(normal_train_data, normal_train_data,\n",
        "                          epochs = 20,\n",
        "                          batch_size = 512,\n",
        "                          validation_data = (test_data, test_data),\n",
        "                          shuffle = True)"
      ],
      "metadata": {
        "id": "FLsw3AWODWL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label = 'Training Loss')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "477bKPs4DdOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = autoencoder.encoder(normal_test_data).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.plot(normal_test_data[0], 'b') # 파란선 : 정상 데이터(원본)\n",
        "plt.plot(decoded_imgs[0], 'r') # 붉은선 : Autoencoder의 결과(만들어진 것)\n",
        "plt.fill_between(np.arange(140), decoded_imgs[0], normal_test_data[0], color = 'lightcoral') # 둘의 차이 = 붉은 영역(Error)\n",
        "plt.legend(labels = ['Input', 'Reconstruction', 'Error'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wIEa2sV7Dlup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터에 대해\n",
        "encoded_imgs = autoencoder.encoder(anomalous_test_data).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "plt.plot(anomalous_test_data[0], 'b') # 파란선 : 정상 데이터(원본)\n",
        "plt.plot(decoded_imgs[0], 'r') # 붉은선 : Autoencoder의 결과(만들어진 것)\n",
        "plt.fill_between(np.arange(140), decoded_imgs[0], anomalous_test_data[0], color = 'lightcoral') # 둘의 차이 = 붉은 영역(Error)\n",
        "plt.legend(labels = ['Input', 'Reconstruction', 'Error'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V-gMzZigD-tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이상 감지 : 임계값을 설정, 이보다 크면 이상이라고 한다\n",
        "- 임계값 설정 : 정상 예제에 대한 평균 오차 계산 -> 재구성 오류가 훈련 세트의 표준편차보다 크다면 예제는 비정상으로 간주"
      ],
      "metadata": {
        "id": "GUD9aAxRES7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(normal_train_data)\n",
        "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data) \n",
        "\n",
        "plt.hist(train_loss, bins = 50)\n",
        "plt.xlabel(\"train loss\")\n",
        "plt.ylabel(\"no of example\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mQwS2yjIEQ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.mean(train_loss) + np.std(train_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "id": "KU_81ACiEuB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(anomalous_test_data)\n",
        "test_loss = tf.keras.losses.mae(reconstructions, anomalous_test_data)\n",
        "\n",
        "plt.hist(test_loss, bins = 50)\n",
        "plt.xlabel(\"Test Loss\")\n",
        "plt.ylabel(\"No of Examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LK7Pu7o6FHQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data, thresohld):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold) # less(x,y) : x < y일 때 True 반환\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, preds)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, preds)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, preds)))"
      ],
      "metadata": {
        "id": "ZHkaIRGaFZlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(autoencoder, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ],
      "metadata": {
        "id": "EHcdqFDtGNsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HMwjS-BOGcKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}